/home/menzzz/anaconda3/envs/py38/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
/home/menzzz/anaconda3/envs/py38/lib/python3.8/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/menzzz/anaconda3/envs/py38/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/menzzz/anaconda3/envs/py38/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
avg_reward -131.71204407375046
[Epoch 1/50] Train Loss: 1.2223 | Val Loss: 0.1109
Traceback (most recent call last):                                                                                                                                      
[Epoch 2/50] Train Loss: 0.0798 | Val Loss: 0.0498
[Epoch 3/50] Train Loss: 0.0331 | Val Loss: 0.0312
[Epoch 4/50] Train Loss: 0.0299 | Val Loss: 0.0244
[Epoch 5/50] Train Loss: 0.0287 | Val Loss: 0.0235
  File "/home/menzzz/2024/learning/RL/project/policy/train.py", line 173, in <module>
    train_dpo_pipeline(
  File "/home/menzzz/2024/learning/RL/project/policy/train.py", line 102, in train_dpo_pipeline
    loss.backward()
  File "/home/menzzz/anaconda3/envs/py38/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/menzzz/anaconda3/envs/py38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
