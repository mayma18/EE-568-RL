{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5b4fba",
   "metadata": {},
   "source": [
    "# üß† RLHF Full Workflow (Unified Notebook)\n",
    "This notebook trains PPO Expert, generates preference data using œÄ‚ÇÅ vs œÄ‚ÇÇ, trains PPO-RLHF using RewardNet, and then trains a DPO policy ‚Äî all within one integrated flow. Supports both discrete and continuous environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecbb4dc",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457cad58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:36:21.905861Z",
     "start_time": "2025-05-15T07:36:21.863949Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33b2db",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf78204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:19:39.157441Z",
     "start_time": "2025-05-15T12:19:39.078475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment: Pendulum-v1 | Action space: Continuous\n"
     ]
    }
   ],
   "source": [
    "# ===== üß© Parameter Settings: Used to control the entire training / preference / visualization process =====\n",
    "\n",
    "env_id = \"Pendulum-v1\"     # Task environment name (Options: CartPole-v1, Pendulum-v1, Acrobot-v1, MountainCar-v0, MountainCarContinuous-v0)\n",
    "\n",
    "seed = 42                  # Random seed to ensure experiment reproducibility\n",
    "\n",
    "total_timesteps = 300_000   # Number of training steps for Expert PPO (Recommended: 40k for CartPole, 300k for Pendulum)\n",
    "num_vec_env = 8\n",
    "\n",
    "num_prefs_traj = 1_000            # Number of preference samples #FF0000\n",
    "sample_prefs = 8_000\n",
    "\n",
    "# ===========================================================\n",
    "\n",
    "\n",
    "set_random_seed(seed)\n",
    "\n",
    "# # Multi Env\n",
    "# vec_env = make_vec_env(\n",
    "#     env_id = env_id,\n",
    "#     n_envs = num_vec_env,\n",
    "# )\n",
    "# env = VecMonitor(vec_env)\n",
    "\n",
    "\n",
    "# Single Env\n",
    "env = gym.make(env_id)\n",
    "env = Monitor(env)\n",
    "num_vec_env = 1\n",
    "\n",
    "is_discrete = hasattr(env.action_space, \"n\")\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if is_discrete else env.action_space.shape[0]\n",
    "sample_length = 500\n",
    "print(f\"‚úÖ Environment: {env_id} | Action space: {'Discrete' if is_discrete else 'Continuous'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f533977",
   "metadata": {},
   "source": [
    "## üß† Step 3: Train PPO Expert (œÄ‚ÇÅ) and Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4413953e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:40:01.669201Z",
     "start_time": "2025-05-15T07:36:25.303665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 2140      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.14e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1191         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036137106 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0082       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.13e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 8.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.14e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1061         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020699282 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.03e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 6.99e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 998         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005652496 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.0724      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+03     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 7.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 969          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059981355 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.019        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 7.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.15e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 958          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035557372 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.0033       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.17e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.948        |\n",
      "|    value_loss           | 9.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.16e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 950          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026940266 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.00572      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.88e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    std                  | 0.931        |\n",
      "|    value_loss           | 5.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 945          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032982763 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.00176      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.96e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 0.931        |\n",
      "|    value_loss           | 8.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 944          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023999477 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.000978     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.3e+03      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 8.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 953          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015800439 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.00146      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.84e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.001       |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 6.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 946          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038937037 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.000788     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.46e+03     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 6.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 941          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044846814 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.000449     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.2e+03      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    std                  | 0.911        |\n",
      "|    value_loss           | 7.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 940          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027967247 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.000564     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.38e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 0.9          |\n",
      "|    value_loss           | 8.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 930          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009454092 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.000551     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000888    |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 5.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 926          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029430245 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.000233     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.49e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 8.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 911          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040861354 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.000373     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.36e+03     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    std                  | 0.888        |\n",
      "|    value_loss           | 7.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.23e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 906         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003455534 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.000287    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.63e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 5.37e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.21e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 903         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004184423 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.000198    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.72e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 6.14e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.21e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 897         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004405112 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.000244    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 4.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 892          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031962674 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.000152     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.04e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.87         |\n",
      "|    value_loss           | 4.47e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.19e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032078046 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 9.59e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.27e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    std                  | 0.872        |\n",
      "|    value_loss           | 5.29e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -1.19e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 885        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00425444 |\n",
      "|    clip_fraction        | 0.0261     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 6.41e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.11e+03   |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.881      |\n",
      "|    value_loss           | 5.42e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 883          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040985253 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 5.63e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.23e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 5.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.15e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 882          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035924222 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 7.02e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.9e+03      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    std                  | 0.879        |\n",
      "|    value_loss           | 4.29e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 882         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003383427 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 5.61e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 3.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.14e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 879          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024948479 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 4.01e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 0.884        |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.13e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 876          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028061457 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 1.48e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000948    |\n",
      "|    std                  | 0.877        |\n",
      "|    value_loss           | 4.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 875          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028699546 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 2.74e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 3.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.13e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 875          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008581034 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 2.56e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000439    |\n",
      "|    std                  | 0.893        |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 874          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030353507 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.79e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 3.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 876          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021875247 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.87e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000784    |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 4.32e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 876         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003180161 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 1.82e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.1e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 877          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019716776 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.51e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 878         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003970334 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 1.47e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 977         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.000971   |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 877          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029812397 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 8.82e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    std                  | 0.91         |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -1.1e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 877        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00416654 |\n",
      "|    clip_fraction        | 0.0341     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 9.42e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.09e+03   |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00259   |\n",
      "|    std                  | 0.917      |\n",
      "|    value_loss           | 2.3e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.08e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 879         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005548319 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 7.09e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 880         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004473949 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 5.78e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 842         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 879         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004523319 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 4.71e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 917         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 879         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006485818 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 4.23e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.904       |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.07e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 880          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041854642 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 4.59e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.07e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 881          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024276022 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 4.11e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    std                  | 0.885        |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.07e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 882         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004471793 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 3.58e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 562         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.07e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 881          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037951546 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 2.56e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 803          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 2.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.06e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 879          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032562576 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 3.04e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 649          |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.899        |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.06e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 879          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034426863 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 2.68e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    std                  | 0.888        |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.06e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 878          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017433102 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 2.8e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 621          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -8.45e-06    |\n",
      "|    std                  | 0.886        |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.05e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 878          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054194964 |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 3.04e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 719          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.05e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 877         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004001994 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 2.86e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 944         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.04e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 878         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005443167 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 2.38e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 727         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.02e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 880          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029791049 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 2.26e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 771          |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    std                  | 0.871        |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.02e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 881          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055086697 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 2.8e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 372          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 0.86         |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1e+03       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 882          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060675573 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 2.5e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 464          |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 918          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.01e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 883          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049567325 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 2.38e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 549          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.866        |\n",
      "|    value_loss           | 1.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -997         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 883          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071230754 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 2.21e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 494          |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    std                  | 0.883        |\n",
      "|    value_loss           | 1.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1e+03       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 883          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067056473 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 3.1e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 372          |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 901          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -998         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 883          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057984795 |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 3.46e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 557          |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -988        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 884         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003825643 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 3.64e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 388         |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    std                  | 0.872       |\n",
      "|    value_loss           | 805         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -979         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 884          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057863845 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 3.4e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 257          |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.866        |\n",
      "|    value_loss           | 725          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -970         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051464587 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 6.08e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 290          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.85         |\n",
      "|    value_loss           | 698          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -970         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068405466 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 367          |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.832        |\n",
      "|    value_loss           | 667          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -969         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049254475 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 284          |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.81         |\n",
      "|    value_loss           | 433          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -967        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 886         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004332189 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    std                  | 0.793       |\n",
      "|    value_loss           | 622         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -954         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049247774 |\n",
      "|    clip_fraction        | 0.0443       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 481          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.775        |\n",
      "|    value_loss           | 747          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -947         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036210725 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 0.77         |\n",
      "|    value_loss           | 548          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -939         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046753585 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 221          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.771        |\n",
      "|    value_loss           | 554          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -924         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036612558 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000408    |\n",
      "|    std                  | 0.768        |\n",
      "|    value_loss           | 518          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -916        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006691275 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.751       |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -923        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004630639 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 285         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    std                  | 0.746       |\n",
      "|    value_loss           | 544         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -924         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052299793 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 171          |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    std                  | 0.741        |\n",
      "|    value_loss           | 431          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -925         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041887425 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.734        |\n",
      "|    value_loss           | 373          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -917         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058537237 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 0.73         |\n",
      "|    value_loss           | 411          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -933        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 890         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003456428 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    std                  | 0.72        |\n",
      "|    value_loss           | 529         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -930         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 891          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057229903 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 203          |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    std                  | 0.711        |\n",
      "|    value_loss           | 440          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -929        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 890         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007222073 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    std                  | 0.71        |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -918         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051114373 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    std                  | 0.711        |\n",
      "|    value_loss           | 336          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -931         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 890          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030450402 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 230          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.696        |\n",
      "|    value_loss           | 395          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -929         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 890          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046346933 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    std                  | 0.701        |\n",
      "|    value_loss           | 447          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -918         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 890          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039759334 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 217          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.7          |\n",
      "|    value_loss           | 496          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -908         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 892          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069966265 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 269          |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.692        |\n",
      "|    value_loss           | 459          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -900         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 893          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036977618 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    std                  | 0.679        |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -882         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 893          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080485465 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    std                  | 0.677        |\n",
      "|    value_loss           | 375          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -852        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006742087 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.7        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    std                  | 0.668       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -839        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 893         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005043247 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    std                  | 0.67        |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -830        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 893         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003820823 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.666       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -807       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 891        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00559898 |\n",
      "|    clip_fraction        | 0.0513     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 81.4       |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.00487   |\n",
      "|    std                  | 0.661      |\n",
      "|    value_loss           | 311        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -767         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 891          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074872375 |\n",
      "|    clip_fraction        | 0.0645       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.997       |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 157          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    std                  | 0.653        |\n",
      "|    value_loss           | 317          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -728        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 891         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008477494 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -681        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 891         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005662781 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    std                  | 0.641       |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -643         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 891          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071430868 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 77.5         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    std                  | 0.632        |\n",
      "|    value_loss           | 302          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -599        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 893         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008040312 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.624       |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -603         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 893          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061517507 |\n",
      "|    clip_fraction        | 0.0906       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 249          |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00842     |\n",
      "|    std                  | 0.625        |\n",
      "|    value_loss           | 352          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -567         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 894          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048656017 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.000484    |\n",
      "|    std                  | 0.625        |\n",
      "|    value_loss           | 549          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -526        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004403837 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.945      |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    std                  | 0.621       |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 200       |\n",
      "|    ep_rew_mean          | -486      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 894       |\n",
      "|    iterations           | 95        |\n",
      "|    time_elapsed         | 217       |\n",
      "|    total_timesteps      | 194560    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0097795 |\n",
      "|    clip_fraction        | 0.0578    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.931    |\n",
      "|    explained_variance   | 0.929     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 181       |\n",
      "|    n_updates            | 940       |\n",
      "|    policy_gradient_loss | -0.00441  |\n",
      "|    std                  | 0.608     |\n",
      "|    value_loss           | 543       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -460        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007288661 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    std                  | 0.591       |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -428        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 896         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007103324 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.9        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    std                  | 0.589       |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -417         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 896          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027288883 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56.9         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    std                  | 0.581        |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -409         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 896          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030282266 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.871       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71.8         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.000574    |\n",
      "|    std                  | 0.575        |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -397       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 897        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00658206 |\n",
      "|    clip_fraction        | 0.0698     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.862     |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24.1       |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.00467   |\n",
      "|    std                  | 0.57       |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -384         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 898          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042676344 |\n",
      "|    clip_fraction        | 0.0891       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.861       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    std                  | 0.573        |\n",
      "|    value_loss           | 99.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -354        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 898         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006640346 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.9        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.588       |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 898         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005196669 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.891      |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.000222    |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -362         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 898          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041288673 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.89        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.588        |\n",
      "|    value_loss           | 437          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -356         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074705505 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.5         |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    std                  | 0.596        |\n",
      "|    value_loss           | 317          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -358         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052322666 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.901       |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    std                  | 0.595        |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -349        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 896         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006379637 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -346         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 896          |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093274545 |\n",
      "|    clip_fraction        | 0.0824       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.887       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.8         |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.583        |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 895         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005210448 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    std                  | 0.573       |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -334         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 895          |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 251          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067330506 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.848       |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    std                  | 0.557        |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -326         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 894          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057805497 |\n",
      "|    clip_fraction        | 0.0777       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    std                  | 0.558        |\n",
      "|    value_loss           | 91.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007372117 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.8         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.558       |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -288         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 894          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033216162 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.829       |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.000544    |\n",
      "|    std                  | 0.551        |\n",
      "|    value_loss           | 72.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 893         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005156612 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.81        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    std                  | 0.561       |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -283        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 892         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009800669 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.000579   |\n",
      "|    std                  | 0.566       |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -275        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 892         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010677127 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.64        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | 0.00209     |\n",
      "|    std                  | 0.56        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -284        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 892         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021191403 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.841      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.14        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | 0.000506    |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 891          |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050333077 |\n",
      "|    clip_fraction        | 0.0974       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.842       |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.68         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    std                  | 0.559        |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -259        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 890         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770588 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.582       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.557       |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -253         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 890          |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049467376 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.833       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.000678    |\n",
      "|    std                  | 0.557        |\n",
      "|    value_loss           | 70           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 890          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070965723 |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.833       |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.19         |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | 0.00359      |\n",
      "|    std                  | 0.553        |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 889         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003472146 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    std                  | 0.547       |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -263         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048536127 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.814       |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55           |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00876     |\n",
      "|    std                  | 0.546        |\n",
      "|    value_loss           | 84.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -266        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007814358 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    std                  | 0.54        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -261        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004277695 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    std                  | 0.542       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056854477 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.796       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.51         |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | 0.00214      |\n",
      "|    std                  | 0.533        |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -253        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009349535 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.000778   |\n",
      "|    std                  | 0.528       |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -272        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 887         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001893904 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -270        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 887         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008435215 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.767      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | 0.00079     |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -277        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 886         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007472159 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.761      |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    std                  | 0.515       |\n",
      "|    value_loss           | 67.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -290         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 886          |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025074289 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.755       |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 321          |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 0.516        |\n",
      "|    value_loss           | 252          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -282         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 305          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047070296 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.758       |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -277        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 886         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008822044 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.75       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -278       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 886        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 274432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00816053 |\n",
      "|    clip_fraction        | 0.0907     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.742     |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 57.1       |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    std                  | 0.511      |\n",
      "|    value_loss           | 156        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -280        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 885         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004444576 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -278        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 885         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010076949 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -4.54e-06   |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -284       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 884        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04935674 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.728     |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | 0.00674    |\n",
      "|    std                  | 0.503      |\n",
      "|    value_loss           | 26.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -315         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037680953 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.738       |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | 0.000393     |\n",
      "|    std                  | 0.509        |\n",
      "|    value_loss           | 255          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -334         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 886          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026650564 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.745       |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 171          |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    std                  | 0.511        |\n",
      "|    value_loss           | 606          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 886          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074109035 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.754       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 0.519        |\n",
      "|    value_loss           | 404          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -336         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047851102 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.759       |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 448          |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.513        |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -347         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 328          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106419055 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.746       |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 54.8         |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.0009      |\n",
      "|    std                  | 0.507        |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -347         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 330          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020621265 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.739       |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.507        |\n",
      "|    value_loss           | 381          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -352        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 885         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002964203 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 541         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -352         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 884          |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 335          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041686418 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.734       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 379          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -344       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 884        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02953802 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.721     |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.22       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | 0.00548    |\n",
      "|    std                  | 0.495      |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 883         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010104677 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.57        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.483       |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = f\"./checkpoints_{env_id.replace('-', '_')}\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=total_timesteps // 10 / num_vec_env,\n",
    "    save_path=checkpoint_dir,\n",
    "    name_prefix=\"ppo\"\n",
    ")\n",
    "\n",
    "expert_model = PPO(\"MlpPolicy\", env, verbose=1, seed=seed, device=\"cpu\")\n",
    "# expert_model = PPO(\"MlpPolicy\", env, verbose=1, seed=seed, device=\"cpu\", n_steps=256)\n",
    "expert_model.learn(total_timesteps=total_timesteps, callback=checkpoint_callback)\n",
    "expert_model.save(f\"{env_id}_expert_seed{seed}.zip\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b14dd",
   "metadata": {},
   "source": [
    "## üß™ Step 4: Select œÄ‚ÇÇ (Half-Performance PPO Checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d6c25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:19:43.526620Z",
     "start_time": "2025-05-15T12:19:41.513298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints_Pendulum_v1\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Best reward: -220.6290466370423\n",
      "Target reward: -441.2580932740846\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "‚úÖ Selected œÄ‚ÇÇ: ppo_180000_steps.zip with ~-532.7 reward\n"
     ]
    }
   ],
   "source": [
    "def evaluate_policy(model, env, episodes=10):\n",
    "    scores = []\n",
    "    for idx in range(episodes):\n",
    "        obs, _ = env.reset(seed=idx)\n",
    "        done = False\n",
    "        total = 0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total += reward\n",
    "        scores.append(total)\n",
    "    return np.mean(scores)\n",
    "\n",
    "env = gym.make(env_id)\n",
    "\n",
    "# checkpoint_dir = \"./checkpoints_Pendulum_v1_Original\"\n",
    "# checkpoint_dir = \"./checkpoints_Pendulum_v1\"\n",
    "\n",
    "print(checkpoint_dir)\n",
    "checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith(\".zip\")])\n",
    "\n",
    "# Loop Start\n",
    "rewards = [(f, evaluate_policy(PPO.load(os.path.join(checkpoint_dir, f), env=env, device=\"cpu\"), env)) for f in checkpoints]\n",
    "\n",
    "best_reward = max(rewards, key=lambda x: x[1])[1]\n",
    "target = best_reward * 2.0 #FF0000 Update from *0.5 to *1.5\n",
    "\n",
    "print(\"Best reward:\", best_reward)\n",
    "print(\"Target reward:\", target)\n",
    "\n",
    "rewards.sort(key=lambda x: abs(x[1] - target))\n",
    "pi2_model = PPO.load(os.path.join(checkpoint_dir, rewards[0][0]), env=env, device=\"cpu\")\n",
    "pi2_model.save(f\"{env_id}_pi2_model_seed{seed}.zip\")\n",
    "print(f\"‚úÖ Selected œÄ‚ÇÇ: {rewards[0][0]} with ~{rewards[0][1]:.1f} reward\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c42fca",
   "metadata": {},
   "source": [
    "## ‚ù§Ô∏è Step 5: Generate Preferences (œÄ‚ÇÅ vs œÄ‚ÇÇ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1dd0f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T10:41:36.607878Z",
     "start_time": "2025-05-15T10:33:05.388587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÑ Generating preference pairs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [02:13<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 1000 preference pairs to prefs_Pendulum-v1_seed42_500.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "def generate_trajectory(model, env, seed, max_steps):\n",
    "    obs_list, act_list, rewards, mask = [], [], [], []\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs_, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        obs_list.append(np.array(obs))       # ensure obs is np.array\n",
    "        act_list.append(np.array(action))    # ensure action is np.array\n",
    "        rewards.append(reward)\n",
    "        mask.append(1)\n",
    "\n",
    "        obs = obs_\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    pad_len = max_steps - len(obs_list)\n",
    "    if pad_len > 0:\n",
    "        obs_shape = obs_list[0].shape\n",
    "        obs_list += [np.zeros(obs_shape)] * pad_len\n",
    "        act_shape = act_list[0].shape if isinstance(act_list[0], np.ndarray) else ()\n",
    "        act_list += [np.zeros(act_shape)] * pad_len\n",
    "        rewards += [0.0] * pad_len\n",
    "        mask += [0] * pad_len\n",
    "\n",
    "    return {\n",
    "        \"obs\": np.stack(obs_list),       # [T, obs_dim]\n",
    "        \"acts\": np.stack(act_list),      # [T] (discrete) or [T, act_dim] (continuous)\n",
    "        \"rews\": np.array(rewards),       # [T]\n",
    "        \"mask\": np.array(mask)           # [T]\n",
    "    }\n",
    "\n",
    "def compute_return(traj):\n",
    "    return sum(traj[\"rews\"])\n",
    "\n",
    "def soft_preference_prob(R1, R2):\n",
    "    max_r = max(R1, R2)\n",
    "    return np.exp(R1 - max_r) / (np.exp(R1 - max_r) + np.exp(R2 - max_r))\n",
    "\n",
    "# Sample preference data\n",
    "prefs = []\n",
    "env = gym.make(env_id)\n",
    "\n",
    "for idx in trange(num_prefs_traj, desc=\"üîÑ Generating preference pairs\"):\n",
    "    traj1 = generate_trajectory(model = expert_model, env=env, seed=idx, max_steps=sample_length)\n",
    "    traj2 = generate_trajectory(model = pi2_model,    env=env, seed=idx, max_steps=sample_length)\n",
    "    R1, R2 = compute_return(traj1), compute_return(traj2)\n",
    "    p = soft_preference_prob(R1, R2)\n",
    "    label = int(np.random.rand() < p)\n",
    "    prefs.append((traj1, traj2, label))\n",
    "\n",
    "# save .pkl\n",
    "filename = f\"prefs_{env_id}_seed{seed}_{sample_length}.pkl\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(prefs, f)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(prefs)} preference pairs to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c970743d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T10:42:15.899371Z",
     "start_time": "2025-05-15T10:42:15.887218Z"
    }
   },
   "outputs": [],
   "source": [
    "class PreferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, prefs, is_discrete):\n",
    "        self.prefs = prefs\n",
    "        self.is_discrete = is_discrete\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prefs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        traj1, traj2, label = self.prefs[idx]\n",
    "\n",
    "        return {\n",
    "            \"obs1\": torch.from_numpy(traj1[\"obs\"]).float(),\n",
    "            \"acts1\": torch.from_numpy(traj1[\"acts\"]).long() if self.is_discrete else torch.from_numpy(traj1[\"acts\"]).float(),\n",
    "            \"mask1\": torch.from_numpy(traj1[\"mask\"]).float(),\n",
    "\n",
    "            \"obs2\": torch.from_numpy(traj2[\"obs\"]).float(),\n",
    "            \"acts2\": torch.from_numpy(traj2[\"acts\"]).long() if self.is_discrete else torch.from_numpy(traj2[\"acts\"]).float(),\n",
    "            \"mask2\": torch.from_numpy(traj2[\"mask\"]).float(),\n",
    "\n",
    "            \"label\": torch.tensor(label, dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9830d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 7: Train DPO Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72faecee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:15:46.106044Z",
     "start_time": "2025-05-15T11:15:45.997376Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# def train_dpo(dataloader, env, seed=0, epochs=25, device='cpu'):\n",
    "#     torch.manual_seed(seed)\n",
    "#     is_discrete = hasattr(env.action_space, \"n\")\n",
    "#     obs_dim = env.observation_space.shape[0]\n",
    "#     act_dim = env.action_space.n if is_discrete else env.action_space.shape[0]\n",
    "    \n",
    "#     model = PPO(\"MlpPolicy\", env, verbose=0, seed=seed, device=device)\n",
    "#     policy = model.policy\n",
    "#     policy.train()  # ensure in training mode\n",
    "#     optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         total_loss = 0\n",
    "#         for batch in dataloader:\n",
    "#             obs1 = batch[\"obs1\"].to(device)      # [B, T, obs_dim]\n",
    "#             acts1 = batch[\"acts1\"].to(device)    # [B, T] or [B, T, act_dim]\n",
    "#             mask1 = batch[\"mask1\"].to(device)    # [B, T]\n",
    "\n",
    "#             obs2 = batch[\"obs2\"].to(device)\n",
    "#             acts2 = batch[\"acts2\"].to(device)\n",
    "#             mask2 = batch[\"mask2\"].to(device)\n",
    "\n",
    "#             labels = batch[\"label\"].to(device)   # [B]\n",
    "\n",
    "#             B, T = obs1.shape[0], obs1.shape[1]\n",
    "\n",
    "#             obs1_flat = obs1.view(-1, obs_dim)\n",
    "#             obs2_flat = obs2.view(-1, obs_dim)\n",
    "#             acts1_flat = acts1.view(-1) if is_discrete else acts1.view(-1, act_dim)\n",
    "#             acts2_flat = acts2.view(-1) if is_discrete else acts2.view(-1, act_dim)\n",
    "\n",
    "#             dist1 = policy.get_distribution(obs1_flat)  # returns Categorical\n",
    "#             dist2 = policy.get_distribution(obs2_flat)\n",
    "#             lp1 = dist1.log_prob(acts1_flat).view(B, T)  # [B, T]\n",
    "#             lp2 = dist2.log_prob(acts2_flat).view(B, T)\n",
    "            \n",
    "#             logp1_sum = (lp1 * mask1).sum(dim=1)  # [B]\n",
    "#             logp2_sum = (lp2 * mask2).sum(dim=1)  # [B]\n",
    "#             logits = logp1_sum - logp2_sum        # [B]\n",
    "\n",
    "#             loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#         avg_loss = total_loss / len(dataloader)\n",
    "#         print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#     return policy\n",
    "\n",
    "with open(f\"prefs_{env_id}_seed{seed}_500.pkl\", \"rb\") as f:\n",
    "    prefs = pickle.load(f)\n",
    "prefs = prefs[:sample_prefs]\n",
    "\n",
    "dataset = PreferenceDataset(prefs, is_discrete)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# dpo_model = train_dpo(loader, env)\n",
    "# torch.save(dpo_model.state_dict(), f\"{env_id}_dpo_seed{seed}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2963075d5b5f3942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:15:48.247228Z",
     "start_time": "2025-05-15T11:15:48.222787Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "def train_dpo_from_ref(dataloader, ref_policy_sb3, env, beta=0.05, seed=42, epochs=25, device='cpu'):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Determine if environment is discrete or continuous\n",
    "    is_discrete = hasattr(env.action_space, \"n\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.n if is_discrete else env.action_space.shape[0]\n",
    "\n",
    "    # Get frozen reference policy from SB3 PPO model\n",
    "    ref_policy = ref_policy_sb3.policy\n",
    "    ref_policy.eval().to(device)\n",
    "\n",
    "    # Create trainable copy of the reference policy\n",
    "    policy = copy.deepcopy(ref_policy)\n",
    "    policy.train().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            # Move batch to device\n",
    "            obs1 = batch[\"obs1\"].to(device)     # [B, T, obs_dim]\n",
    "            acts1 = batch[\"acts1\"].to(device)   # [B, T] or [B, T, act_dim]\n",
    "            mask1 = batch[\"mask1\"].to(device)   # [B, T]\n",
    "\n",
    "            obs2 = batch[\"obs2\"].to(device)\n",
    "            acts2 = batch[\"acts2\"].to(device)\n",
    "            mask2 = batch[\"mask2\"].to(device)\n",
    "\n",
    "            labels = batch[\"label\"].to(device)  # [B]\n",
    "\n",
    "            B, T = obs1.shape[:2]\n",
    "\n",
    "            # Flatten time dimension for easier batch processing\n",
    "            obs1_flat = obs1.view(-1, obs_dim)\n",
    "            obs2_flat = obs2.view(-1, obs_dim)\n",
    "            acts1_flat = acts1.view(-1) if is_discrete else acts1.view(-1, act_dim)\n",
    "            acts2_flat = acts2.view(-1) if is_discrete else acts2.view(-1, act_dim)\n",
    "\n",
    "            # --- Compute log-probs from trainable policy ---\n",
    "            dist1 = policy.get_distribution(obs1_flat)\n",
    "            dist2 = policy.get_distribution(obs2_flat)\n",
    "            logp1 = dist1.log_prob(acts1_flat)\n",
    "            logp2 = dist2.log_prob(acts2_flat)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                dist1_ref = ref_policy.get_distribution(obs1_flat)\n",
    "                dist2_ref = ref_policy.get_distribution(obs2_flat)\n",
    "                logp1_ref = dist1_ref.log_prob(acts1_flat)\n",
    "                logp2_ref = dist2_ref.log_prob(acts2_flat)\n",
    "\n",
    "            if not is_discrete:\n",
    "                # Ensure log-probs are at least 1D\n",
    "                if logp1.dim() > 1:\n",
    "                    logp1 = logp1.sum(-1)\n",
    "                    logp2 = logp2.sum(-1)\n",
    "                    logp1_ref = logp1_ref.sum(-1)\n",
    "                    logp2_ref = logp2_ref.sum(-1)\n",
    "\n",
    "            lp1 = (logp1 - logp1_ref).view(B, -1)\n",
    "            lp2 = (logp2 - logp2_ref).view(B, -1)\n",
    "\n",
    "            # Mask padded tokens\n",
    "            logp1_sum = (lp1 * mask1).sum(dim=1)\n",
    "            logp2_sum = (lp2 * mask2).sum(dim=1)\n",
    "\n",
    "            # Compute logits for DPO loss\n",
    "            logits = beta * (logp1_sum - logp2_sum)  # [B]\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "            # Backprop and update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd0f181690278a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:09:39.129047Z",
     "start_time": "2025-05-15T10:42:30.248284Z"
    }
   },
   "outputs": [],
   "source": [
    "# def eval_policy(model, env, is_sb3=True, episodes=20):\n",
    "#     returns = []\n",
    "#     for idx in range(episodes):\n",
    "#         obs, _ = env.reset(seed=idx)\n",
    "#         total = 0.0\n",
    "#         done = False\n",
    "#         while not done:\n",
    "#             action = model.predict(obs, deterministic=True)[0] if is_sb3 else model.select_action(obs)\n",
    "#             obs, reward, terminated, truncated, _ = env.step(action)\n",
    "#             done = terminated or truncated\n",
    "#             total += reward\n",
    "#         returns.append(total)\n",
    "#     return returns\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def fine_tune_dpo_with_betas(env, dataloader, pi2_model, beta_values_from_ref, beta_values, epochs=25, device='cpu'):\n",
    "#     rewards_from_ref = {}\n",
    "#     rewards = {}\n",
    "\n",
    "#     obs_dim = env.observation_space.shape[0]\n",
    "#     is_discrete = hasattr(env.action_space, \"n\")\n",
    "#     act_dim = env.action_space.n if is_discrete else env.action_space.shape[0]\n",
    "\n",
    "#     # ‚úÖ Train DPO starting from œÄ‚ÇÇ and moving toward expert\n",
    "#     for beta in beta_values_from_ref:\n",
    "#         print(f\"Training DPO (œÄ‚ÇÇ ‚Üí Expert) with Œ≤ = {beta}\")\n",
    "\n",
    "#         trained_policy_from_ref = train_dpo_from_ref(\n",
    "#             dataloader=dataloader,\n",
    "#             ref_policy_sb3=pi2_model,\n",
    "#             env=env,\n",
    "#             beta=beta,\n",
    "#             epochs=epochs,\n",
    "#             device=device\n",
    "#         )\n",
    "\n",
    "#         avg_reward = np.mean(eval_policy(trained_policy_from_ref, env, episodes=10))\n",
    "#         print(f\"Final avg reward for Œ≤ = {beta}: {avg_reward:.2f}\")\n",
    "#         rewards_from_ref[beta] = avg_reward\n",
    "\n",
    "\n",
    "#     trained_policy = train_dpo(\n",
    "#             dataloader=dataloader,\n",
    "#             env=env,\n",
    "#             epochs=epochs,\n",
    "#             device=device\n",
    "#     )\n",
    "\n",
    "#     avg_reward = np.mean(eval_policy(trained_policy, env, episodes=10))\n",
    "#     print(f\"Final avg reward for Œ≤ = {beta}: {avg_reward:.2f}\")\n",
    "#     rewards[beta] = avg_reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # ‚úÖ Plot both curves\n",
    "#     plt.figure(figsize=(9, 5))\n",
    "#     plt.plot(list(rewards_from_ref.keys()), list(rewards_from_ref.values()), marker='o', label=\"DPO from œÄ‚ÇÇ\")\n",
    "#     plt.plot(list(rewards.keys()), list(rewards.values()), marker='s', label=\"DPO baseline\")\n",
    "#     plt.xlabel(\"Œ≤ (temperature)\")\n",
    "#     plt.ylabel(\"Final Avg Reward\")\n",
    "#     plt.title(\"DPO Fine-Tuning: œÄ‚ÇÇ ‚Üí Expert vs Baseline\")\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     return rewards_from_ref, rewards\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open(f\"prefs_{env_id}_seed{seed}_500.pkl\", \"rb\") as f:\n",
    "#     prefs = pickle.load(f)\n",
    "# prefs = prefs[:sample_prefs]\n",
    "\n",
    "# dataset = PreferenceDataset(prefs, is_discrete)\n",
    "# loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# beta_values_from_ref =np.arange(0.25,2,0.25)\n",
    "# beta_values = np.arange(1, 2, 1)\n",
    "# # we could also potentially choose an adaptive beta, like : beta = beta_init * (epoch / max_epochs)\n",
    "\n",
    "\n",
    "# '''\n",
    "# When I increase Œ≤, I am being more conservative and penalizing drift from pi_ref.\n",
    "# When I decrease Œ≤, I allow the model to explore more and drift away from pi_ref.\n",
    "\n",
    "# Becasue pi2 is close to expert, B do not play a key role here\n",
    "\n",
    "# '''\n",
    "\n",
    "\n",
    "# rewards_from_ref, rewards = fine_tune_dpo_with_betas(env, loader, pi2_model,beta_values_from_ref,beta_values=beta_values)\n",
    "# beta_from_ref = max(rewards_from_ref, key = rewards_from_ref.get)\n",
    "# #beta_from_ref = 0.5\n",
    "# print(f\"--------------------------------we use beta = {beta_from_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f24b1da6a9ba05f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:21:46.626920Z",
     "start_time": "2025-05-15T11:16:05.595528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DPO (œÄ‚ÇÇ ‚Üí Expert) with Œ≤ = 0.5\n",
      "Epoch 1/25, Loss: 0.0818\n",
      "Epoch 2/25, Loss: 0.0527\n",
      "Epoch 3/25, Loss: 0.0530\n",
      "Epoch 4/25, Loss: 0.0316\n",
      "Epoch 5/25, Loss: 0.0360\n",
      "Epoch 6/25, Loss: 0.0884\n",
      "Epoch 7/25, Loss: 0.1305\n",
      "Epoch 8/25, Loss: 0.0967\n",
      "Epoch 9/25, Loss: 0.0755\n",
      "Epoch 10/25, Loss: 0.0929\n",
      "Epoch 11/25, Loss: 0.0615\n",
      "Epoch 12/25, Loss: 0.0668\n",
      "Epoch 13/25, Loss: 0.0903\n",
      "Epoch 14/25, Loss: 0.0678\n",
      "Epoch 15/25, Loss: 0.0403\n",
      "Epoch 16/25, Loss: 0.0505\n",
      "Epoch 17/25, Loss: 0.0738\n",
      "Epoch 18/25, Loss: 0.0490\n",
      "Epoch 19/25, Loss: 0.0563\n",
      "Epoch 20/25, Loss: 0.0387\n",
      "Epoch 21/25, Loss: 0.0357\n",
      "Epoch 22/25, Loss: 0.0532\n",
      "Epoch 23/25, Loss: 0.0424\n",
      "Epoch 24/25, Loss: 0.0776\n",
      "Epoch 25/25, Loss: 0.0485\n"
     ]
    }
   ],
   "source": [
    "beta_from_ref = 0.5\n",
    "\n",
    "# Train DPO from œÄ‚ÇÇ to Expert\n",
    "print(f\"Training DPO (œÄ‚ÇÇ ‚Üí Expert) with Œ≤ = {beta_from_ref}\")\n",
    "dpo_model_from_ref = train_dpo_from_ref(loader,pi2_model, env, beta=beta_from_ref, seed=seed)\n",
    "torch.save(dpo_model_from_ref.state_dict(), f\"{env_id}_dpo_pi2_seed{seed}.pth\")\n",
    "\n",
    "# # Train DPO from scratch\n",
    "# print(\"Training DPO (from scratch)\")\n",
    "# dpo_model = train_dpo(loader, env, seed=seed)\n",
    "# torch.save(dpo_model.state_dict(), f\"{env_id}_dpo_seed{seed}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808861c5",
   "metadata": {},
   "source": [
    "## üß† Step 8: Train RewardNet from Preferences (for PPO-RLHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2d93920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.0347\n",
      "Epoch 2/50, Loss: 0.0332\n",
      "Epoch 3/50, Loss: 0.0334\n",
      "Epoch 4/50, Loss: 0.0327\n",
      "Epoch 5/50, Loss: 0.0280\n",
      "Epoch 6/50, Loss: 0.0264\n",
      "Epoch 7/50, Loss: 0.0259\n",
      "Epoch 8/50, Loss: 0.0252\n",
      "Epoch 9/50, Loss: 0.0254\n",
      "Epoch 10/50, Loss: 0.0244\n",
      "Epoch 11/50, Loss: 0.0248\n",
      "Epoch 12/50, Loss: 0.0238\n",
      "Epoch 13/50, Loss: 0.0245\n",
      "Epoch 14/50, Loss: 0.0229\n",
      "Epoch 15/50, Loss: 0.0242\n",
      "Epoch 16/50, Loss: 0.0217\n",
      "Epoch 17/50, Loss: 0.0219\n",
      "Epoch 18/50, Loss: 0.0215\n",
      "Epoch 19/50, Loss: 0.0218\n",
      "Epoch 20/50, Loss: 0.0206\n",
      "Epoch 21/50, Loss: 0.0202\n",
      "Epoch 22/50, Loss: 0.0209\n",
      "Epoch 23/50, Loss: 0.0208\n",
      "Epoch 24/50, Loss: 0.0202\n",
      "Epoch 25/50, Loss: 0.0217\n",
      "Epoch 26/50, Loss: 0.0216\n",
      "Epoch 27/50, Loss: 0.0197\n",
      "Epoch 28/50, Loss: 0.0196\n",
      "Epoch 29/50, Loss: 0.0202\n",
      "Epoch 30/50, Loss: 0.0190\n",
      "Epoch 31/50, Loss: 0.0196\n",
      "Epoch 32/50, Loss: 0.0200\n",
      "Epoch 33/50, Loss: 0.0205\n",
      "Epoch 34/50, Loss: 0.0194\n",
      "Epoch 35/50, Loss: 0.0183\n",
      "Epoch 36/50, Loss: 0.0173\n",
      "Epoch 37/50, Loss: 0.0177\n",
      "Epoch 38/50, Loss: 0.0185\n",
      "Epoch 39/50, Loss: 0.0173\n",
      "Epoch 40/50, Loss: 0.0192\n",
      "Epoch 41/50, Loss: 0.0174\n",
      "Epoch 42/50, Loss: 0.0167\n",
      "Epoch 43/50, Loss: 0.0171\n",
      "Epoch 44/50, Loss: 0.0173\n",
      "Epoch 45/50, Loss: 0.0174\n",
      "Epoch 46/50, Loss: 0.0167\n",
      "Epoch 47/50, Loss: 0.0207\n",
      "Epoch 48/50, Loss: 0.0181\n",
      "Epoch 49/50, Loss: 0.0159\n",
      "Epoch 50/50, Loss: 0.0164\n"
     ]
    }
   ],
   "source": [
    "class RewardNet(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, is_discrete=True, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.is_discrete = is_discrete\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim + act_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, states, actions):\n",
    "        if self.is_discrete:\n",
    "            one_hot = F.one_hot(actions.view(-1), num_classes=self.act_dim).float()\n",
    "            x = torch.cat([states, one_hot], dim=-1)\n",
    "        else:\n",
    "            x = torch.cat([states, actions], dim=-1)\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "def train_reward_model(dataloader, obs_dim, act_dim, is_discrete, epochs=50, lr=1e-3, device='cpu'):\n",
    "    model = RewardNet(obs_dim, act_dim, is_discrete).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            obs1 = batch[\"obs1\"].to(device)      # [B, T, obs_dim]\n",
    "            acts1 = batch[\"acts1\"].to(device)    # [B, T] or [B, T, act_dim]\n",
    "            mask1 = batch[\"mask1\"].to(device)    # [B, T]\n",
    "\n",
    "            obs2 = batch[\"obs2\"].to(device)\n",
    "            acts2 = batch[\"acts2\"].to(device)\n",
    "            mask2 = batch[\"mask2\"].to(device)\n",
    "\n",
    "            labels = batch[\"label\"].to(device)   # [B]\n",
    "\n",
    "            r1 = model(obs1.view(-1, obs_dim), acts1.view(-1) if is_discrete else acts1.view(-1, act_dim))\n",
    "            r2 = model(obs2.view(-1, obs_dim), acts2.view(-1) if is_discrete else acts2.view(-1, act_dim))\n",
    "\n",
    "            r1 = r1.view(obs1.shape[0], obs1.shape[1]) * mask1\n",
    "            r2 = r2.view(obs2.shape[0], obs2.shape[1]) * mask2\n",
    "\n",
    "            r1_sum = r1.sum(dim=1)  # [B]\n",
    "            r2_sum = r2.sum(dim=1)  # [B]\n",
    "\n",
    "            logits = r1_sum - r2_sum  # [B]\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "with open(f\"prefs_{env_id}_seed{seed}_500.pkl\", \"rb\") as f:\n",
    "    prefs = pickle.load(f)\n",
    "prefs = prefs[:sample_prefs]\n",
    "\n",
    "dataset = PreferenceDataset(prefs, is_discrete=is_discrete)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "reward_model = train_reward_model(loader, obs_dim, act_dim, is_discrete)\n",
    "torch.save(reward_model.state_dict(), f\"{env_id}_reward_model_seed{seed}.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631661a",
   "metadata": {},
   "source": [
    "## üîÅ Step 9: Train PPO-RLHF (Reward Finetuned from Expert œÄ‚ÇÅ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pendulum-v1_pi2_model_seed42.zip\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -67.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 1481     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class RewardNetWrapper(Wrapper):\n",
    "    def __init__(self, env, reward_net, is_discrete):\n",
    "        super().__init__(env)\n",
    "        self.reward_net = reward_net\n",
    "        self.is_discrete = is_discrete\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        # Convert to tensor\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        if self.is_discrete:\n",
    "            act_tensor = torch.tensor(action, dtype=torch.long).unsqueeze(0)\n",
    "        else:\n",
    "            act_tensor = torch.tensor(action, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Predict learned reward\n",
    "        with torch.no_grad():\n",
    "            reward = self.reward_net(obs_tensor, act_tensor).item()\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "# Wrap the environment with the trained reward_net\n",
    "reward_model.eval()  # Ensure the model is in inference mode\n",
    "env = RewardNetWrapper(gym.make(env_id), reward_model, is_discrete)\n",
    "env = Monitor(env)\n",
    "\n",
    "# Retrain the policy using the new reward\n",
    "path_model_pi_2 = f\"{env_id}_pi2_model_seed{seed}.zip\"\n",
    "print(path_model_pi_2)\n",
    "\n",
    "# rlhf_model = PPO(\"MlpPolicy\", env, verbose=1, seed=seed, device=\"cpu\")\n",
    "rlhf_model = PPO.load(path   = path_model_pi_2, \n",
    "                      env    = env, \n",
    "                      seed   = seed, \n",
    "                      device = \"cpu\",\n",
    "                      kl_coeff = 0.2,\n",
    "                      target_kl= 0.02)  # KL penalty coefficient 0.01\n",
    "\n",
    "# rlhf_model.learn(total_timesteps=total_timesteps)\n",
    "# rlhf_model.learn(total_timesteps=total_timesteps // 2) #FF0000\n",
    "rlhf_model.learn(total_timesteps=30000) #FF0000\n",
    "rlhf_model.save(f\"{env_id}_rlhf_pi2_seed{seed}.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542fb06",
   "metadata": {},
   "source": [
    "## üìä Step 10: Compare PPO Expert vs PPO-RLHF vs DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa15fc4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:48:11.877772Z",
     "start_time": "2025-05-15T12:48:07.032153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:36: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:53: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:54: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:53: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:54: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:36: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  labels=[\"Expert ($\\pi_1$)\",\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:37: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"$\\pi_2$ RLHF\",\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:38: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"$\\pi_2$\",\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:39: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"$\\pi_2$ DPO\"],\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:52: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  labels=[\"Expert ($\\pi_1$)\",\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:53: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"$\\pi_2$\",\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:54: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"DPO from $\\pi_2$\"],\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:57: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  axes[1].set_title(\"Focused: Expert, œÄ‚ÇÇ,DPO from $\\pi_2$\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:32: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[0].boxplot([returns_pi1,\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\1441503657.py:48: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[1].boxplot([returns_pi1,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to Pendulum-v1_dual_benchmark_42_dataset8000.png\n"
     ]
    }
   ],
   "source": [
    "def eval_policy(model, env, episodes=50):\n",
    "    returns = []\n",
    "    for idx in range(episodes):\n",
    "        obs, _ = env.reset(seed=idx)\n",
    "        total = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = model.predict(obs, deterministic=True)[0]\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total += reward\n",
    "        returns.append(total)\n",
    "    return returns\n",
    "\n",
    "\n",
    "env = gym.make(env_id)\n",
    "returns_pi1    = eval_policy(PPO.load(f\"{env_id}_expert_seed{seed}.zip\", env=env, device=\"cpu\"), env)\n",
    "returns_pi2    = eval_policy(PPO.load(f\"{env_id}_pi2_model_seed{seed}.zip\", env=env, device=\"cpu\"), env)\n",
    "returns_pi2_rlhf   = eval_policy(PPO.load(f\"{env_id}_rlhf_pi2_seed{seed}.zip\", env=env, device=\"cpu\"), env)\n",
    "state_dict = torch.load(f\"{env_id}_dpo_seed{seed}.pth\", weights_only=True)\n",
    "model_pi2_dpo = PPO(\"MlpPolicy\", env, verbose=0, seed=seed, device=\"cpu\")\n",
    "model_pi2_dpo.policy.load_state_dict(torch.load(f\"{env_id}_dpo_pi2_seed{seed}.pth\", weights_only=True))\n",
    "returns_pi2_dpo = eval_policy(model_pi2_dpo, env)\n",
    "\n",
    "# print(returns_pi1)\n",
    "# print(returns_pi2)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# First subplot: Full comparison\n",
    "axes[0].boxplot([returns_pi1, \n",
    "                 returns_pi2_rlhf, \n",
    "                 returns_pi2, \n",
    "                 returns_pi2_dpo],\n",
    "                labels=[\"Expert ($\\pi_1$)\", \n",
    "                        \"$\\pi_2$ RLHF\", \n",
    "                        \"$\\pi_2$\", \n",
    "                        \"$\\pi_2$ DPO\"],\n",
    "                showmeans=True)\n",
    "\n",
    "axes[0].set_title(\"Full Policy Comparison\")\n",
    "axes[0].set_ylabel(\"Episode Return\")\n",
    "axes[0].set_ylim([-2000, 0])\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Second subplot: Only DPO, œÄ‚ÇÅ, and œÄ‚ÇÇ\n",
    "axes[1].boxplot([returns_pi1, \n",
    "                 returns_pi2, \n",
    "                 returns_pi2_dpo],\n",
    "\n",
    "                labels=[\"Expert ($\\pi_1$)\", \n",
    "                        \"$\\pi_2$\", \n",
    "                        \"DPO from $\\pi_2$\"],\n",
    "\n",
    "                showmeans=True)\n",
    "axes[1].set_title(\"Focused: Expert, œÄ‚ÇÇ,DPO from $\\pi_2$\")\n",
    "axes[1].set_ylim([-400, 0])\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{env_id}_dual_benchmark_{seed}_dataset{sample_prefs}.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved to\", f\"{env_id}_dual_benchmark_{seed}_dataset{sample_prefs}.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdfa2300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:27:24.122536Z",
     "start_time": "2025-05-15T11:26:55.791907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:66: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\692635252.py:66: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  titles = [\"Expert\", \"RLHF\", \"DPO\", \"$\\pi_2$\", \"DPO from $\\pi_2$\"]\n",
      "C:\\Users\\MATH-286-Dell\\AppData\\Local\\Temp\\ipykernel_22640\\692635252.py:66: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  titles = [\"Expert\", \"RLHF\", \"DPO\", \"$\\pi_2$\", \"DPO from $\\pi_2$\"]\n",
      "c:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Pendulum-v1_rlhf_seed42.zip.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m env_dpo_from_pi2 \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(env_id, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m expert_model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_expert_seed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m=\u001b[39menv_expert)\n\u001b[1;32m---> 87\u001b[0m rlhf_model   \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43menv_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_rlhf_seed\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_rlhf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m dpo_model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[0;32m     89\u001b[0m pi2_model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pi2_model_seed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m=\u001b[39menv_pi2)\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:681\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m     get_system_info()\n\u001b[1;32m--> 681\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:403\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[1;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[0;32m    377\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[0;32m    378\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\functools.py:907\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    905\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:240\u001b[0m, in \u001b[0;36mopen_path_str\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:291\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    285\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:272\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    270\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:264\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1012\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Pendulum-v1_rlhf_seed42.zip.zip'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "# Step 1: Run a single episode and record rendered frames\n",
    "def record_episode(model, env, seed, max_steps=1000):\n",
    "    frames = []\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    for _ in range(max_steps):\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "        action = model.predict(obs, deterministic=True)[0]\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    env.close()\n",
    "    return frames\n",
    "\n",
    "# Step 2: Combine multiple frame sequences into a single animation and optionally save as a GIF\n",
    "def show_combined_animation(frames_list, fps=30, gif_path=None):\n",
    "    min_len = min(len(f) for f in frames_list)\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.axis('off')\n",
    "    init_frame = np.hstack([f[0] for f in frames_list])\n",
    "    im = plt.imshow(init_frame)\n",
    "\n",
    "    def update(i):\n",
    "        combined = np.hstack([f[i] for f in frames_list])\n",
    "        im.set_array(combined)\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=min_len, interval=1000/fps)\n",
    "\n",
    "    if gif_path:\n",
    "        ani.save(gif_path, writer='pillow', fps=fps)\n",
    "        print(f\"‚úÖ GIF saved to: {os.path.abspath(gif_path)}\")\n",
    "\n",
    "    return HTML(ani.to_jshtml())\n",
    "\n",
    "def trajectory_overlay_faded(frames, threshold=30, min_alpha=0.05, max_alpha=0.6):\n",
    "    frames = [f.astype(np.float32) for f in frames]\n",
    "    H, W, C = frames[0].shape\n",
    "\n",
    "    overlay = np.ones((H, W, C), dtype=np.float32) * 255\n",
    "    num_frames = len(frames)\n",
    "\n",
    "    for idx, frame in enumerate(frames):\n",
    "        diff = np.abs(frame - 255)\n",
    "        mask = (diff.mean(axis=2) > threshold)\n",
    "\n",
    "        alpha = min_alpha + (max_alpha - min_alpha) * (idx / (num_frames - 1))\n",
    "\n",
    "        for c in range(3):\n",
    "            overlay[:, :, c][mask] = (\n",
    "                alpha * frame[:, :, c][mask] +\n",
    "                (1 - alpha) * overlay[:, :, c][mask]\n",
    "            )\n",
    "    return np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "\n",
    "def show_trajectory_comparison(img_expert, img_rlhf, img_dpo, img_pi2, img_dpo_from_pi2, titles=None):\n",
    "    if titles is None:\n",
    "        titles = [\"Expert\", \"RLHF\", \"DPO\", \"$\\pi_2$\", \"DPO from $\\pi_2$\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(18, 6))\n",
    "    images = [img_expert, img_rlhf, img_dpo, img_pi2, img_dpo_from_pi2]\n",
    "\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{env_id}_render_{seed}_dataset{sample_prefs}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Load models and environments\n",
    "# Step 4: Load models and environments\n",
    "env_expert = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "env_rlhf   = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "env_dpo    = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "env_pi2 = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "env_dpo_from_pi2 = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "expert_model = PPO.load(f\"{env_id}_expert_seed{seed}.zip\", env=env_expert)\n",
    "rlhf_model   = PPO.load(f\"{env_id}_rlhf_seed{seed}.zip\", env=env_rlhf)\n",
    "dpo_model.policy.load_state_dict(state_dict)\n",
    "pi2_model = PPO.load(f\"{env_id}_pi2_model_seed{seed}.zip\", env=env_pi2)\n",
    "dpo_from_pi2 = copy.deepcopy(pi2_model.policy)\n",
    "dpo_from_pi2.load_state_dict(torch.load(f\"{env_id}_dpo_pi2_seed{seed}.pth\"))\n",
    "\n",
    "# Step 5: Collect animation frames for all three strategies\n",
    "frames_expert = record_episode(expert_model, env_expert, seed=seed)\n",
    "frames_rlhf   = record_episode(rlhf_model, env_rlhf, seed=seed)\n",
    "frames_dpo    = record_episode(dpo_model, env_dpo, seed=seed)\n",
    "frames_pi2 = record_episode(pi2_model, env_pi2, seed=seed)\n",
    "frames_dpo_from_pi2 = record_episode(dpo_from_pi2, env_dpo_from_pi2, seed=seed)\n",
    "\n",
    "# Step 6: Display the combined animation and save it as a GIF file\n",
    "display(HTML(\"<h3>üéØ Strategy Animation Comparison: PPO Expert vs RLHF vs DPO</h3> vs PI2 vs DPO_PI2\"))\n",
    "display(show_combined_animation(\n",
    "    [frames_expert, frames_rlhf, frames_dpo, frames_pi2, frames_dpo_from_pi2],\n",
    "    gif_path=f\"{env_id}_comparison_seed{seed}_dataset{sample_prefs}.gif\"\n",
    "))\n",
    "\n",
    "img_expert = trajectory_overlay_faded(frames_expert, threshold=55)\n",
    "img_rlhf = trajectory_overlay_faded(frames_rlhf, threshold=55)\n",
    "img_dpo = trajectory_overlay_faded(frames_dpo, threshold=55)\n",
    "img_pi2 = trajectory_overlay_faded(frames_pi2, threshold=55)\n",
    "img_dpo_from_pi2 = trajectory_overlay_faded(frames_dpo_from_pi2, threshold=55)\n",
    "show_trajectory_comparison(img_expert, img_rlhf, img_dpo, img_pi2, img_dpo_from_pi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14870b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81207945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
